{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "8dedca56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "import h5py\n",
    "import io\n",
    "from PIL import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "2df7292d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1150 383\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>isic_id</th>\n",
       "      <th>target</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>sex</th>\n",
       "      <th>anatom_site_general</th>\n",
       "      <th>clin_size_long_diam_mm</th>\n",
       "      <th>image_type</th>\n",
       "      <th>tbp_tile_type</th>\n",
       "      <th>...</th>\n",
       "      <th>tbp_lv_stdL</th>\n",
       "      <th>tbp_lv_stdLExt</th>\n",
       "      <th>tbp_lv_symm_2axis</th>\n",
       "      <th>tbp_lv_symm_2axis_angle</th>\n",
       "      <th>tbp_lv_x</th>\n",
       "      <th>tbp_lv_y</th>\n",
       "      <th>tbp_lv_z</th>\n",
       "      <th>attribution</th>\n",
       "      <th>copyright_license</th>\n",
       "      <th>tbp_lv_dnn_lesion_confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>103295</td>\n",
       "      <td>ISIC_2633129</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_5967999</td>\n",
       "      <td>50.0</td>\n",
       "      <td>male</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>2.93</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>...</td>\n",
       "      <td>4.721150</td>\n",
       "      <td>1.790725</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>150</td>\n",
       "      <td>144.579400</td>\n",
       "      <td>1308.924000</td>\n",
       "      <td>121.037400</td>\n",
       "      <td>Department of Dermatology, Hospital Clínic de ...</td>\n",
       "      <td>CC-BY-NC</td>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>366034</td>\n",
       "      <td>ISIC_9134117</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_6630831</td>\n",
       "      <td>45.0</td>\n",
       "      <td>male</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>2.53</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: white</td>\n",
       "      <td>...</td>\n",
       "      <td>1.325075</td>\n",
       "      <td>2.326877</td>\n",
       "      <td>0.295455</td>\n",
       "      <td>0</td>\n",
       "      <td>-172.972100</td>\n",
       "      <td>1098.591000</td>\n",
       "      <td>-14.055240</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-BY</td>\n",
       "      <td>99.995950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>390561</td>\n",
       "      <td>ISIC_9735344</td>\n",
       "      <td>1</td>\n",
       "      <td>IP_0786235</td>\n",
       "      <td>55.0</td>\n",
       "      <td>female</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>3.55</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: white</td>\n",
       "      <td>...</td>\n",
       "      <td>1.617953</td>\n",
       "      <td>1.622337</td>\n",
       "      <td>0.259615</td>\n",
       "      <td>0</td>\n",
       "      <td>-257.329895</td>\n",
       "      <td>145.011108</td>\n",
       "      <td>76.742126</td>\n",
       "      <td>Memorial Sloan Kettering Cancer Center</td>\n",
       "      <td>CC-BY</td>\n",
       "      <td>99.780303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>373505</td>\n",
       "      <td>ISIC_9316446</td>\n",
       "      <td>0</td>\n",
       "      <td>IP_1974761</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>anterior torso</td>\n",
       "      <td>5.50</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>...</td>\n",
       "      <td>2.495571</td>\n",
       "      <td>1.769214</td>\n",
       "      <td>0.394030</td>\n",
       "      <td>95</td>\n",
       "      <td>26.420441</td>\n",
       "      <td>1107.199829</td>\n",
       "      <td>187.676758</td>\n",
       "      <td>University Hospital of Basel</td>\n",
       "      <td>CC-BY-NC</td>\n",
       "      <td>60.856247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>390188</td>\n",
       "      <td>ISIC_9726753</td>\n",
       "      <td>1</td>\n",
       "      <td>IP_2870467</td>\n",
       "      <td>45.0</td>\n",
       "      <td>male</td>\n",
       "      <td>posterior torso</td>\n",
       "      <td>3.97</td>\n",
       "      <td>TBP tile: close-up</td>\n",
       "      <td>3D: XP</td>\n",
       "      <td>...</td>\n",
       "      <td>1.647755</td>\n",
       "      <td>2.437316</td>\n",
       "      <td>0.278261</td>\n",
       "      <td>145</td>\n",
       "      <td>10.437012</td>\n",
       "      <td>1550.156250</td>\n",
       "      <td>184.937683</td>\n",
       "      <td>Frazer Institute, The University of Queensland...</td>\n",
       "      <td>CC-BY</td>\n",
       "      <td>99.999261</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0       isic_id  target  patient_id  age_approx     sex  \\\n",
       "405       103295  ISIC_2633129       0  IP_5967999        50.0    male   \n",
       "1426      366034  ISIC_9134117       0  IP_6630831        45.0    male   \n",
       "373       390561  ISIC_9735344       1  IP_0786235        55.0  female   \n",
       "1053      373505  ISIC_9316446       0  IP_1974761        75.0    male   \n",
       "372       390188  ISIC_9726753       1  IP_2870467        45.0    male   \n",
       "\n",
       "     anatom_site_general  clin_size_long_diam_mm          image_type  \\\n",
       "405      posterior torso                    2.93  TBP tile: close-up   \n",
       "1426      anterior torso                    2.53  TBP tile: close-up   \n",
       "373      lower extremity                    3.55  TBP tile: close-up   \n",
       "1053      anterior torso                    5.50  TBP tile: close-up   \n",
       "372      posterior torso                    3.97  TBP tile: close-up   \n",
       "\n",
       "     tbp_tile_type  ...  tbp_lv_stdL  tbp_lv_stdLExt  tbp_lv_symm_2axis  \\\n",
       "405         3D: XP  ...     4.721150        1.790725           0.177778   \n",
       "1426     3D: white  ...     1.325075        2.326877           0.295455   \n",
       "373      3D: white  ...     1.617953        1.622337           0.259615   \n",
       "1053        3D: XP  ...     2.495571        1.769214           0.394030   \n",
       "372         3D: XP  ...     1.647755        2.437316           0.278261   \n",
       "\n",
       "      tbp_lv_symm_2axis_angle    tbp_lv_x     tbp_lv_y    tbp_lv_z  \\\n",
       "405                       150  144.579400  1308.924000  121.037400   \n",
       "1426                        0 -172.972100  1098.591000  -14.055240   \n",
       "373                         0 -257.329895   145.011108   76.742126   \n",
       "1053                       95   26.420441  1107.199829  187.676758   \n",
       "372                       145   10.437012  1550.156250  184.937683   \n",
       "\n",
       "                                            attribution  copyright_license  \\\n",
       "405   Department of Dermatology, Hospital Clínic de ...           CC-BY-NC   \n",
       "1426             Memorial Sloan Kettering Cancer Center              CC-BY   \n",
       "373              Memorial Sloan Kettering Cancer Center              CC-BY   \n",
       "1053                       University Hospital of Basel           CC-BY-NC   \n",
       "372   Frazer Institute, The University of Queensland...              CC-BY   \n",
       "\n",
       "      tbp_lv_dnn_lesion_confidence  \n",
       "405                     100.000000  \n",
       "1426                     99.995950  \n",
       "373                      99.780303  \n",
       "1053                     60.856247  \n",
       "372                      99.999261  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir = \"isic-2024-challenge\"\n",
    "df = pd.read_csv(f\"clean-metadata.csv\")\n",
    "df_target1 = df[df['target'] == 1]\n",
    "df_target0 = df[df['target'] == 0]\n",
    "df_target0_sampled = df_target0.sample(frac=0.003, random_state=42)\n",
    "print(len(df_target0_sampled), len(df_target1))\n",
    "df = pd.concat([df_target1, df_target0_sampled]).reset_index(drop=True)\n",
    "df = df.sample(frac=1)\n",
    "train_img = f\"{dir}/train-image/image\"\n",
    "train_hdf5 = f\"{dir}/train-image.hdf5\"\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "6649e4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\n",
    "    \"age_approx\",\n",
    "    \"clin_size_long_diam_mm\",\n",
    "    \"tbp_lv_A\",\n",
    "    \"tbp_lv_Aext\",\n",
    "    \"tbp_lv_B\",\n",
    "    \"tbp_lv_Bext\",\n",
    "    \"tbp_lv_C\",\n",
    "    \"tbp_lv_Cext\",\n",
    "    \"tbp_lv_H\",\n",
    "    \"tbp_lv_Hext\",\n",
    "    \"tbp_lv_L\",\n",
    "    \"tbp_lv_Lext\",\n",
    "    \"tbp_lv_areaMM2\",\n",
    "    \"tbp_lv_area_perim_ratio\",\n",
    "    \"tbp_lv_color_std_mean\",\n",
    "    \"tbp_lv_deltaA\",\n",
    "    \"tbp_lv_deltaB\",\n",
    "    \"tbp_lv_deltaL\",\n",
    "    \"tbp_lv_deltaLB\",\n",
    "    \"tbp_lv_deltaLBnorm\",\n",
    "    \"tbp_lv_eccentricity\",\n",
    "    \"tbp_lv_minorAxisMM\",\n",
    "    \"tbp_lv_nevi_confidence\",\n",
    "    \"tbp_lv_norm_border\",\n",
    "    \"tbp_lv_norm_color\",\n",
    "    \"tbp_lv_perimeterMM\",\n",
    "    \"tbp_lv_radial_color_std_max\",\n",
    "    \"tbp_lv_stdL\",\n",
    "    \"tbp_lv_stdLExt\",\n",
    "    \"tbp_lv_symm_2axis\",\n",
    "    \"tbp_lv_symm_2axis_angle\",\n",
    "    \"tbp_lv_x\",\n",
    "    \"tbp_lv_y\",\n",
    "    \"tbp_lv_z\",\n",
    "    \"tbp_lv_dnn_lesion_confidence\",\n",
    "]\n",
    "categoric_cols = ['sex', 'anatom_site_general', \"tbp_lv_location\", \"tbp_lv_location_simple\"]\n",
    "\n",
    "df_categorical = pd.get_dummies(df[categoric_cols], drop_first=True)\n",
    "df_numeric = df[numeric_cols].copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df_numeric[numeric_cols] = scaler.fit_transform(df_numeric[numeric_cols])\n",
    "\n",
    "processed = pd.concat([df_numeric, df_categorical], axis=1)\n",
    "\n",
    "clean_df = df.copy()\n",
    "for col in processed.columns:\n",
    "    clean_df[col] = processed[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "99a4e034",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_isic_image(isic_id, file_path, num_channels=3, as_array=False):\n",
    "    \"\"\"\n",
    "    Decodes an ISIC image from an HDF5 file.\n",
    "\n",
    "    The HDF5 file is expected to store images with keys corresponding to their ISIC IDs.\n",
    "    The image can be stored either as encoded bytes (JPEG, PNG, etc.) or as a raw NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "        isic_id (str): The ISIC identifier referencing the image in the HDF5 file.\n",
    "        file_path (str): The path to the HDF5 file.\n",
    "        num_channels (int): The expected number of channels in the image. For example, 1 for grayscale,\n",
    "                            3 for RGB, or 4 for RGBA.\n",
    "        as_array (bool): If True, returns a NumPy array; otherwise returns a PIL Image (default).\n",
    "\n",
    "    Returns:\n",
    "        PIL.Image.Image or numpy.ndarray: The decoded image.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the image cannot be found or decoded, or if the image channels do not\n",
    "                    match the expected number.\n",
    "    \"\"\"\n",
    "    # Open the HDF5 file and retrieve the image using its ISIC ID.\n",
    "    with h5py.File(file_path, \"r\") as hf:\n",
    "        try:\n",
    "            # Adjust this line if the images are stored under a subgroup (e.g., hf['images'][isic_id]).\n",
    "            data = hf[isic_id][()]\n",
    "        except KeyError:\n",
    "            raise ValueError(f\"Image with ISIC ID '{isic_id}' not found in the HDF5 file.\")\n",
    "\n",
    "    # Case 1: The data is stored as encoded image bytes.\n",
    "    if isinstance(data, bytes):\n",
    "        image = Image.open(io.BytesIO(data))\n",
    "\n",
    "    # Case 2: The data is stored as a raw NumPy array.\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        # If the image is grayscale (2D array) and one channel is expected:\n",
    "        if data.ndim == 2 and num_channels == 1:\n",
    "            image = Image.fromarray(data, mode='L')\n",
    "        # For color images, we expect a 3D array.\n",
    "        elif data.ndim == 3:\n",
    "            if data.shape[2] == num_channels:\n",
    "                if num_channels == 1:\n",
    "                    # Squeeze the extra dimension for grayscale.\n",
    "                    image = Image.fromarray(data.squeeze(), mode='L')\n",
    "                elif num_channels == 3:\n",
    "                    image = Image.fromarray(data, mode='RGB')\n",
    "                elif num_channels == 4:\n",
    "                    image = Image.fromarray(data, mode='RGBA')\n",
    "                else:\n",
    "                    # For uncommon channel counts, fall back to default conversion.\n",
    "                    image = Image.fromarray(data)\n",
    "            else:\n",
    "                raise ValueError(f\"Expected {num_channels} channels, but found {data.shape[2]} channels in the image data.\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported image data shape in the HDF5 file.\")\n",
    "\n",
    "    # Case 3: Attempt to convert any other type to bytes and decode.\n",
    "    else:\n",
    "        try:\n",
    "            data_bytes = bytes(data)\n",
    "            image = Image.open(io.BytesIO(data_bytes))\n",
    "        except Exception as e:\n",
    "            raise ValueError(\"Could not decode image from the HDF5 file data.\") from e\n",
    "\n",
    "    if as_array:\n",
    "        return np.array(image)\n",
    "    else:\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "59221d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SkinLesionData(Dataset):\n",
    "    def __init__(self, csv_file, img_dir, hdf5_path, transform=None):\n",
    "        self.df = csv_file\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.hdf5_path = hdf5_path\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        isic_id = row[\"isic_id\"]\n",
    "        label = int(row[\"target\"])\n",
    "        \n",
    "        image = decode_isic_image(isic_id, self.hdf5_path, num_channels=3, as_array=False)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc2a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "\n",
    "train_transforms = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.RandomCrop(224),\n",
    "    T.RandomHorizontalFlip(p=0.5),\n",
    "    T.RandomVerticalFlip(p=0.3),\n",
    "    T.RandomRotation(45),\n",
    "    T.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    T.RandomAffine(degrees=0, translate=(0.15, 0.15)),\n",
    "    T.RandomPerspective(distortion_scale=0.2, p=0.3),\n",
    "    T.GaussianBlur(kernel_size=3, sigma=(0.1, 0.5)),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "73cdfe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "dataset = SkinLesionData(csv_file=df, img_dir=train_img, hdf5_path=train_hdf5, transform=train_transforms)\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=0)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e8565e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "# Unfreeze last two blocks\n",
    "for param in model.layer4.parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.layer3.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 512),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.7),\n",
    "    nn.Linear(512, 1)\n",
    ")\n",
    "model = model.to('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ed6350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30] Train Loss: 0.3779, Train Acc: 0.9199, Val Loss: 0.7510, Val Acc: 0.8674\n",
      "Epoch [2/30] Train Loss: 0.3146, Train Acc: 0.9189, Val Loss: 0.6322, Val Acc: 0.8804\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "pos_weight = torch.tensor([len(df_target0_sampled) / len(df_target1)]).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weight)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=5e-5, weight_decay=1e-3)\n",
    "\n",
    "num_epochs = 30\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward\n",
    "        outputs = model(images)       # shape: (batch_size, 2)\n",
    "        loss = criterion(outputs, labels.unsqueeze(1).float())\n",
    "        \n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Accumulate training metrics\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        predicted = (outputs > 0.5).float().squeeze()\n",
    "        correct += (predicted == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "    \n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels.unsqueeze(1).float())\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            \n",
    "            predicted = (outputs > 0.5).float().squeeze()\n",
    "            val_correct += (predicted == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "    \n",
    "    val_loss /= val_total\n",
    "    val_acc = val_correct / val_total\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] \"\n",
    "          f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d539a61",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[146]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m weights = model.fc[\u001b[32m0\u001b[39m].weight.data\n\u001b[32m      2\u001b[39m feature_importance = torch.sum(torch.abs(weights), dim=\u001b[32m0\u001b[39m).cpu().numpy()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m importance_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfeature\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocessed\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimportance\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfeature_importance\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m.sort_values(\u001b[33m'\u001b[39m\u001b[33mimportance\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(importance_df.head(\u001b[32m30\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    772\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    773\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    774\u001b[39m     )\n\u001b[32m    776\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    777\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m778\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    779\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    780\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         index = \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\lucas\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:677\u001b[39m, in \u001b[36m_extract_index\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    675\u001b[39m lengths = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[32m    676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAll arrays must be of the same length\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    681\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    682\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "weights = model.fc[0].weight.data  # Shape: [hidden_units, num_features]\n",
    "\n",
    "# Compute feature importance\n",
    "feature_importance = torch.sum(torch.abs(weights), dim=0).cpu().numpy().flatten()\n",
    "\n",
    "# Create DataFrame (ensure processed.columns matches weights.shape[1])\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': list(processed.columns),  # Convert to list\n",
    "    'importance': feature_importance\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(importance_df.head(30))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
